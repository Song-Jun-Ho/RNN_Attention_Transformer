{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-Jun-Ho/RNN_Attention_Transformer/blob/main/hw4_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxtMC2g66gQ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj2CXov7JJqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a595a74-8d75-4b52-cf6a-43882017c63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcKp4bZiJwut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bfb524-7622-434f-f62f-ee4bada83561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HW4\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/HW4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHKo6dP6eEO6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n",
        "\n",
        "from data import prepareData\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# TRAIN_RATIO: train dataset ratio, should be a float in (0, 0.8]\n",
        "# (0.8-TRAIN_RATIO) will be used for valid dataset\n",
        "TRAIN_RATIO = 0.6 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util"
      ],
      "metadata": {
        "id": "Kz2VM-9MIyKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do NOT Modify** code blocks in this section"
      ],
      "metadata": {
        "id": "8qCY42PE0kRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOnSsL1EeG85"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, clip):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch[0].to(device)\n",
        "        trg = batch[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        loss = loss_fn(output, trg)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "UHo7XkIGIz2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch[0].to(device)\n",
        "            trg = batch[1].to(device)\n",
        "\n",
        "            output = model(src, trg)\n",
        "\n",
        "            loss = loss_fn(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "l2-jeXr-I1yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PgCsIyawXoN"
      },
      "source": [
        "## Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do NOT Modify** code blocks in this section"
      ],
      "metadata": {
        "id": "40ZOR80S0wet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "VALID_RATIO = 0.8-TRAIN_RATIO\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "jwwJGiyETHsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fePBsU2GKoaI",
        "outputId": "a4760df1-580b-43d3-e110-a448a1a52ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "data example\n",
            "['tu me fais de l ombre .', 'you re blocking my light .']\n"
          ]
        }
      ],
      "source": [
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, max_length=10, fra2eng=True):\n",
        "        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n",
        "        self.max_length=max_length\n",
        "\n",
        "        self.input_lang.addWord('PAD')\n",
        "        self.output_lang.addWord('PAD')\n",
        "        self.input_lang_pad = self.input_lang.word2index['PAD']\n",
        "        self.output_lang_pad = self.output_lang.word2index['PAD']\n",
        "        \n",
        "        print(\"data example\")\n",
        "        print(random.choice(self.pairs))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.pairs[idx]\n",
        "        x, y = self._tensorsFromPair(pair)\n",
        "        return x, y\n",
        "\n",
        "    def _tensorFromSentence(self, lang, sentence):\n",
        "        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "        indexes.append(EOS_token)\n",
        "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "    def _tensorsFromPair(self, pair):\n",
        "        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n",
        "        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n",
        "        return (input_tensor, target_tensor)\n",
        "    \n",
        "    def collate_fn(self, data):\n",
        "        x_batch = []; y_batch = []\n",
        "        \n",
        "        for x, y in data:\n",
        "            if x.shape[0] < self.max_length-1:\n",
        "                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n",
        "            elif x.shape[0] > self.max_length-1:\n",
        "                x = x[:self.max_length-1]\n",
        "            if y.shape[0] < self.max_length-1:\n",
        "                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n",
        "            elif y.shape[0] > self.max_length-1:\n",
        "                y = y[:self.max_length-1]\n",
        "\n",
        "            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n",
        "            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n",
        "        \n",
        "        return torch.stack(x_batch), torch.stack(y_batch)\n",
        "\n",
        "dataset = TranslateDataset(max_length=MAX_LENGTH)\n",
        "\n",
        "train_size = int(len(dataset)*TRAIN_RATIO)\n",
        "valid_size = int(len(dataset)*VALID_RATIO)\n",
        "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TqutY58tG-h"
      },
      "source": [
        "# 1. Seq2Seq model with Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5xyf2mHuhmX"
      },
      "source": [
        "## Implement LSTM Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, emb_dim, hid_dim, dropout):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(in_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        '''\n",
        "        INPUT\n",
        "        - input: input sentence, (B, max_len)\n",
        "        - hidden: initialized hidden state, (1, B, hid_dim)\n",
        "        - cell: initialized cell state, (1, B, hid_dim)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n",
        "        Feel free to return outputs you need.\n",
        "        some examples below\n",
        "        - hidden states of encoder\n",
        "\n",
        "        '''\n",
        "        \n",
        "        input_embed = self.dropout_layer(self.embedding(input)) # (B, max_len, emb_dim)\n",
        "        \n",
        "        enc_hiddens, (hidden, cell) = self.lstm(input_embed, (hidden, cell)) # enc_hiddens -> (B, max_len, hid_dim)\n",
        "        \n",
        "        return enc_hiddens"
      ],
      "metadata": {
        "id": "1MM6lL95JcDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnLSTMDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n",
        "        super(AttnLSTMDecoder, self).__init__()\n",
        "        \n",
        "        self.t = 0 # (t)th token decoder\n",
        "        self.enc_hiddens = enc_hiddens # encoder output (B, L, hid_dim)\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(out_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hid_dim, out_dim)\n",
        "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        '''\n",
        "        INPUT\n",
        "        - input: input sentence (B, 1) -> y_(i-1)\n",
        "        - hidden: previous hidden state (1, B, hid_dim) -> s_(i-1)\n",
        "        - cell: previous cell state (1, B, hid_dim)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below\n",
        "        - predicted token embedding (N, emb_dim)\n",
        "        - current hidden state\n",
        "        - current cell state\n",
        "        '''\n",
        "        # s_i = f(s_(i-1), y_(i-1), c_i)\n",
        "        query = hidden.squeeze(0) # set query to calculate attention\n",
        "        query = torch.unsqueeze(query, dim=2) # query (B, hid_dim, 1) -> s_(i-1), self.enc_hiddens (B, L, hid_dim)\n",
        "        attn_score = torch.matmul(self.enc_hiddens, query)  # (B, L, 1)\n",
        "        attn_coef = F.softmax(attn_score, dim=1)\n",
        "        attn_val = (attn_coef * self.enc_hiddens).sum(dim=1, keepdim=True)  # (B, 1, hid_dim) -> c_i\n",
        "        #attn_val = self.dropout_layer(attn_val)\n",
        "\n",
        "        input_embed = self.dropout_layer(self.embedding(input))   # (B, 1, emb_dim) -> y_(i-1)\n",
        "        input_cat = torch.concat([input_embed, attn_val], dim=-1)  # (B, 1, emb_dim + hid_dim) -> lstm input\n",
        "        \n",
        "        hiddens, (hidden, cell) = self.lstm(input_cat, (hidden, cell))  # hiddens -> (B, 1, hid_dim)\n",
        "        hidden_dropout = self.dropout_layer(hidden.squeeze(0))\n",
        "        oh_token_pred = F.log_softmax(self.classifier(hidden_dropout), dim=1) # (B, out_dim)\n",
        "        pred_token_idx = oh_token_pred.max(1)[1].unsqueeze(1) # (B, 1)\n",
        "\n",
        "        self.t += 1 # update time for each forward\n",
        "\n",
        "        return oh_token_pred, pred_token_idx, hidden, cell\n"
      ],
      "metadata": {
        "id": "VPQnZdz5KKnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda import device_count\n",
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n",
        "        super(LSTMSeq2Seq, self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.encoder = LSTMEncoder(in_dim, emb_dim, hid_dim, dropout)\n",
        "        self.decoder = AttnLSTMDecoder(emb_dim, hid_dim, out_dim, dropout)\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        '''\n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - trg: target language batched data (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - output of one-hot prediction (B, out_dim, max_len)\n",
        "        '''\n",
        "        batch_size, mx_len = src.shape\n",
        "\n",
        "        # Encoder (start from zero-hidden & zero-cell states)\n",
        "        init_hidden = torch.zeros(1, batch_size, self.hid_dim).to(self.device)\n",
        "        init_cell = torch.zeros(1, batch_size, self.hid_dim).to(self.device)\n",
        "        enc_hiddens = self.encoder(src, init_hidden, init_cell) # (B, L, hid_dim)\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder.enc_hiddens = enc_hiddens # set encoder's hidden states\n",
        "        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n",
        "        \n",
        "        # Decoder hidden/cell initialization\n",
        "        hidden = enc_hiddens[:, -1, :].unsqueeze(0)   # (1, B, hid_dim)\n",
        "        cell = torch.zeros(1, batch_size, self.hid_dim).to(self.device)   # (1, B, hid_dim)\n",
        "\n",
        "        # First output token [SOS]\n",
        "        # trg -> (B, mx_len) => [SOS] : (B, 1) -> (B, 1, emb_dim)\n",
        "        input = trg[:, 0].unsqueeze(1) # (B, 1)\n",
        "        \n",
        "        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n",
        "            oh_token_pred, input, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t-1] = oh_token_pred  # oh_token_pred -> (B, num_output_words)\n",
        "\n",
        "        self.decoder.t=0 # after for loop, reset decoder's time to evaluate properly\n",
        "\n",
        "        outputs = torch.permute(outputs, (1, 2, 0))\n",
        "        # outputs -> (L, B, num_output_words) => (B, num_output_words, L)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "zJsJ3p2NLD6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu3WP3mYw3NV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QQgN03XecUV"
      },
      "outputs": [],
      "source": [
        "in_dim = dataset.input_lang.n_words\n",
        "out_dim = dataset.output_lang.n_words\n",
        "hid_dim = 1024 #256\n",
        "emb_dim = 1024 #256\n",
        "dropout = 0.3\n",
        "learning_rate=1e-4\n",
        "N_EPOCHS = 100\n",
        "valid_every=5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "\n",
        "from torch.optim.lr_scheduler import MultiStepLR as MultiStepLR\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[50], gamma=0.1)\n",
        "loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbSR6BZKf-6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f198bf93-244c-42d5-bee6-d1783ee35f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 4.1722699 | Train PPL:  64.863\n",
            "==========================\n",
            "\t Val. Loss: 3.083 |  Val. PPL:  21.825\n",
            "Epoch: 02\n",
            "\tTrain Loss: 2.9440387 | Train PPL:  18.992\n",
            "Epoch: 03\n",
            "\tTrain Loss: 2.7089903 | Train PPL:  15.014\n",
            "Epoch: 04\n",
            "\tTrain Loss: 2.5704601 | Train PPL:  13.072\n",
            "Epoch: 05\n",
            "\tTrain Loss: 2.4729254 | Train PPL:  11.857\n",
            "Epoch: 06\n",
            "\tTrain Loss: 2.3784143 | Train PPL:  10.788\n",
            "==========================\n",
            "\t Val. Loss: 2.382 |  Val. PPL:  10.827\n",
            "Epoch: 07\n",
            "\tTrain Loss: 2.2857578 | Train PPL:   9.833\n",
            "Epoch: 08\n",
            "\tTrain Loss: 2.1964184 | Train PPL:   8.993\n",
            "Epoch: 09\n",
            "\tTrain Loss: 2.1079584 | Train PPL:   8.231\n",
            "Epoch: 10\n",
            "\tTrain Loss: 2.0355800 | Train PPL:   7.657\n",
            "Epoch: 11\n",
            "\tTrain Loss: 1.9681651 | Train PPL:   7.158\n",
            "==========================\n",
            "\t Val. Loss: 2.134 |  Val. PPL:   8.445\n",
            "Epoch: 12\n",
            "\tTrain Loss: 1.8989067 | Train PPL:   6.679\n",
            "Epoch: 13\n",
            "\tTrain Loss: 1.8368327 | Train PPL:   6.277\n",
            "Epoch: 14\n",
            "\tTrain Loss: 1.7700354 | Train PPL:   5.871\n",
            "Epoch: 15\n",
            "\tTrain Loss: 1.7116026 | Train PPL:   5.538\n",
            "Epoch: 16\n",
            "\tTrain Loss: 1.6582836 | Train PPL:   5.250\n",
            "==========================\n",
            "\t Val. Loss: 1.985 |  Val. PPL:   7.282\n",
            "Epoch: 17\n",
            "\tTrain Loss: 1.6077558 | Train PPL:   4.992\n",
            "Epoch: 18\n",
            "\tTrain Loss: 1.5531197 | Train PPL:   4.726\n",
            "Epoch: 19\n",
            "\tTrain Loss: 1.4974085 | Train PPL:   4.470\n",
            "Epoch: 20\n",
            "\tTrain Loss: 1.4525075 | Train PPL:   4.274\n",
            "Epoch: 21\n",
            "\tTrain Loss: 1.3988681 | Train PPL:   4.051\n",
            "==========================\n",
            "\t Val. Loss: 1.864 |  Val. PPL:   6.448\n",
            "Epoch: 22\n",
            "\tTrain Loss: 1.3459709 | Train PPL:   3.842\n",
            "Epoch: 23\n",
            "\tTrain Loss: 1.3021683 | Train PPL:   3.677\n",
            "Epoch: 24\n",
            "\tTrain Loss: 1.2604735 | Train PPL:   3.527\n",
            "Epoch: 25\n",
            "\tTrain Loss: 1.2170334 | Train PPL:   3.377\n",
            "Epoch: 26\n",
            "\tTrain Loss: 1.1697061 | Train PPL:   3.221\n",
            "==========================\n",
            "\t Val. Loss: 1.797 |  Val. PPL:   6.034\n",
            "Epoch: 27\n",
            "\tTrain Loss: 1.1331024 | Train PPL:   3.105\n",
            "Epoch: 28\n",
            "\tTrain Loss: 1.0938146 | Train PPL:   2.986\n",
            "Epoch: 29\n",
            "\tTrain Loss: 1.0562910 | Train PPL:   2.876\n",
            "Epoch: 30\n",
            "\tTrain Loss: 1.0110489 | Train PPL:   2.748\n",
            "Epoch: 31\n",
            "\tTrain Loss: 0.9776507 | Train PPL:   2.658\n",
            "==========================\n",
            "\t Val. Loss: 1.711 |  Val. PPL:   5.537\n",
            "Epoch: 32\n",
            "\tTrain Loss: 0.9429998 | Train PPL:   2.568\n",
            "Epoch: 33\n",
            "\tTrain Loss: 0.9021695 | Train PPL:   2.465\n",
            "Epoch: 34\n",
            "\tTrain Loss: 0.8680585 | Train PPL:   2.382\n",
            "Epoch: 35\n",
            "\tTrain Loss: 0.8329592 | Train PPL:   2.300\n",
            "Epoch: 36\n",
            "\tTrain Loss: 0.7942021 | Train PPL:   2.213\n",
            "==========================\n",
            "\t Val. Loss: 1.693 |  Val. PPL:   5.435\n",
            "Epoch: 37\n",
            "\tTrain Loss: 0.7620473 | Train PPL:   2.143\n",
            "Epoch: 38\n",
            "\tTrain Loss: 0.7299311 | Train PPL:   2.075\n",
            "Epoch: 39\n",
            "\tTrain Loss: 0.7069657 | Train PPL:   2.028\n",
            "Epoch: 40\n",
            "\tTrain Loss: 0.6717554 | Train PPL:   1.958\n",
            "Epoch: 41\n",
            "\tTrain Loss: 0.6404937 | Train PPL:   1.897\n",
            "==========================\n",
            "\t Val. Loss: 1.652 |  Val. PPL:   5.218\n",
            "Epoch: 42\n",
            "\tTrain Loss: 0.6176785 | Train PPL:   1.855\n",
            "Epoch: 43\n",
            "\tTrain Loss: 0.5883021 | Train PPL:   1.801\n",
            "Epoch: 44\n",
            "\tTrain Loss: 0.5568364 | Train PPL:   1.745\n",
            "Epoch: 45\n",
            "\tTrain Loss: 0.5323849 | Train PPL:   1.703\n",
            "Epoch: 46\n",
            "\tTrain Loss: 0.5063996 | Train PPL:   1.659\n",
            "==========================\n",
            "\t Val. Loss: 1.595 |  Val. PPL:   4.926\n",
            "Epoch: 47\n",
            "\tTrain Loss: 0.4823074 | Train PPL:   1.620\n",
            "Epoch: 48\n",
            "\tTrain Loss: 0.4567103 | Train PPL:   1.579\n",
            "Epoch: 49\n",
            "\tTrain Loss: 0.4358498 | Train PPL:   1.546\n",
            "Epoch: 50\n",
            "\tTrain Loss: 0.4087943 | Train PPL:   1.505\n",
            "Epoch: 51\n",
            "\tTrain Loss: 0.3675505 | Train PPL:   1.444\n",
            "==========================\n",
            "\t Val. Loss: 1.584 |  Val. PPL:   4.875\n",
            "Epoch: 52\n",
            "\tTrain Loss: 0.3557192 | Train PPL:   1.427\n",
            "Epoch: 53\n",
            "\tTrain Loss: 0.3523183 | Train PPL:   1.422\n",
            "Epoch: 54\n",
            "\tTrain Loss: 0.3426768 | Train PPL:   1.409\n",
            "Epoch: 55\n",
            "\tTrain Loss: 0.3391776 | Train PPL:   1.404\n",
            "Epoch: 56\n",
            "\tTrain Loss: 0.3373513 | Train PPL:   1.401\n",
            "==========================\n",
            "\t Val. Loss: 1.596 |  Val. PPL:   4.934\n",
            "Epoch: 57\n",
            "\tTrain Loss: 0.3324836 | Train PPL:   1.394\n",
            "Epoch: 58\n",
            "\tTrain Loss: 0.3281956 | Train PPL:   1.388\n",
            "Epoch: 59\n",
            "\tTrain Loss: 0.3257055 | Train PPL:   1.385\n",
            "Epoch: 60\n",
            "\tTrain Loss: 0.3245431 | Train PPL:   1.383\n",
            "Epoch: 61\n",
            "\tTrain Loss: 0.3209643 | Train PPL:   1.378\n",
            "==========================\n",
            "\t Val. Loss: 1.577 |  Val. PPL:   4.843\n",
            "Epoch: 62\n",
            "\tTrain Loss: 0.3184608 | Train PPL:   1.375\n",
            "Epoch: 63\n",
            "\tTrain Loss: 0.3144645 | Train PPL:   1.370\n",
            "Epoch: 64\n",
            "\tTrain Loss: 0.3093319 | Train PPL:   1.363\n",
            "Epoch: 65\n",
            "\tTrain Loss: 0.3093386 | Train PPL:   1.363\n",
            "Epoch: 66\n",
            "\tTrain Loss: 0.3061538 | Train PPL:   1.358\n",
            "==========================\n",
            "\t Val. Loss: 1.605 |  Val. PPL:   4.977\n",
            "Epoch: 67\n",
            "\tTrain Loss: 0.3029648 | Train PPL:   1.354\n",
            "Epoch: 68\n",
            "\tTrain Loss: 0.3007477 | Train PPL:   1.351\n",
            "Epoch: 69\n",
            "\tTrain Loss: 0.2992110 | Train PPL:   1.349\n",
            "Epoch: 70\n",
            "\tTrain Loss: 0.2985794 | Train PPL:   1.348\n",
            "Epoch: 71\n",
            "\tTrain Loss: 0.2939409 | Train PPL:   1.342\n",
            "==========================\n",
            "\t Val. Loss: 1.589 |  Val. PPL:   4.898\n",
            "Epoch: 72\n",
            "\tTrain Loss: 0.2901445 | Train PPL:   1.337\n",
            "Epoch: 73\n",
            "\tTrain Loss: 0.2886846 | Train PPL:   1.335\n",
            "Epoch: 74\n",
            "\tTrain Loss: 0.2876460 | Train PPL:   1.333\n",
            "Epoch: 75\n",
            "\tTrain Loss: 0.2849393 | Train PPL:   1.330\n",
            "Epoch: 76\n",
            "\tTrain Loss: 0.2821976 | Train PPL:   1.326\n",
            "==========================\n",
            "\t Val. Loss: 1.593 |  Val. PPL:   4.920\n",
            "Epoch: 77\n",
            "\tTrain Loss: 0.2773218 | Train PPL:   1.320\n",
            "Epoch: 78\n",
            "\tTrain Loss: 0.2801041 | Train PPL:   1.323\n",
            "Epoch: 79\n",
            "\tTrain Loss: 0.2751837 | Train PPL:   1.317\n",
            "Epoch: 80\n",
            "\tTrain Loss: 0.2758615 | Train PPL:   1.318\n",
            "Epoch: 81\n",
            "\tTrain Loss: 0.2710904 | Train PPL:   1.311\n",
            "==========================\n",
            "\t Val. Loss: 1.632 |  Val. PPL:   5.114\n",
            "Epoch: 82\n",
            "\tTrain Loss: 0.2691634 | Train PPL:   1.309\n",
            "Epoch: 83\n",
            "\tTrain Loss: 0.2667024 | Train PPL:   1.306\n",
            "Epoch: 84\n",
            "\tTrain Loss: 0.2676500 | Train PPL:   1.307\n",
            "Epoch: 85\n",
            "\tTrain Loss: 0.2631335 | Train PPL:   1.301\n",
            "Epoch: 86\n",
            "\tTrain Loss: 0.2594598 | Train PPL:   1.296\n",
            "==========================\n",
            "\t Val. Loss: 1.623 |  Val. PPL:   5.067\n",
            "Epoch: 87\n",
            "\tTrain Loss: 0.2592723 | Train PPL:   1.296\n",
            "Epoch: 88\n",
            "\tTrain Loss: 0.2579872 | Train PPL:   1.294\n",
            "Epoch: 89\n",
            "\tTrain Loss: 0.2561155 | Train PPL:   1.292\n",
            "Epoch: 90\n",
            "\tTrain Loss: 0.2544349 | Train PPL:   1.290\n",
            "Epoch: 91\n",
            "\tTrain Loss: 0.2513827 | Train PPL:   1.286\n",
            "==========================\n",
            "\t Val. Loss: 1.592 |  Val. PPL:   4.915\n",
            "Epoch: 92\n",
            "\tTrain Loss: 0.2497050 | Train PPL:   1.284\n",
            "Epoch: 93\n",
            "\tTrain Loss: 0.2458911 | Train PPL:   1.279\n",
            "Epoch: 94\n",
            "\tTrain Loss: 0.2473386 | Train PPL:   1.281\n",
            "Epoch: 95\n",
            "\tTrain Loss: 0.2446047 | Train PPL:   1.277\n",
            "Epoch: 96\n",
            "\tTrain Loss: 0.2406844 | Train PPL:   1.272\n",
            "==========================\n",
            "\t Val. Loss: 1.631 |  Val. PPL:   5.110\n",
            "Epoch: 97\n",
            "\tTrain Loss: 0.2392262 | Train PPL:   1.270\n",
            "Epoch: 98\n",
            "\tTrain Loss: 0.2367724 | Train PPL:   1.267\n",
            "Epoch: 99\n",
            "\tTrain Loss: 0.2362432 | Train PPL:   1.266\n",
            "Epoch: 100\n",
            "\tTrain Loss: 0.2344443 | Train PPL:   1.264\n"
          ]
        }
      ],
      "source": [
        "# Train your model\n",
        "train_loss_list = []    # for every epoch\n",
        "valid_loss_list = []    # for every 5 epochs\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    train_loss_list.append(train_loss)\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.7f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n",
        "        valid_loss_list.append(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            model.decoder.t=0\n",
        "            torch.save(model.state_dict(), 'lstm-attn-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train/validation loss visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(np.arange(1, N_EPOCHS+1), train_loss_list)\n",
        "#plt.plot(np.arange(1, N_EPOCHS, valid_every), valid_loss_list)\n",
        "plt.title('Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dFoX4R1TrGpk",
        "outputId": "081b21d3-1432-4bba-88cb-cc7a54f8fd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(1, N_EPOCHS+1, valid_every), valid_loss_list)\n",
        "plt.title('Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "39Uss0oKxSqc",
        "outputId": "323d5db3-2637-43d5-f229-76b28561661d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "\n",
        "loaded_model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "loaded_model.load_state_dict(torch.load('lstm-attn-model.pt'))\n",
        "\n",
        "test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"
      ],
      "metadata": {
        "id": "hBXKAKZo2lSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e0fded-502e-4094-bdf3-e749eac66c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Test. Loss: 1.547 |  Test. PPL:   4.697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Bonus] Implement GRU Seq2Seq Model"
      ],
      "metadata": {
        "id": "FD1SYbuKOKGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, emb_dim, hid_dim, dropout):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(in_dim, emb_dim)\n",
        "        self.gru = nn.GRU(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input_embed = self.dropout_layer(self.embedding(input)) # (B, max_len, emb_dim)\n",
        "        \n",
        "        enc_hiddens, hidden = self.gru(input_embed, hidden) # enc_hiddens -> (B, max_len, hid_dim)\n",
        "        \n",
        "        return enc_hiddens"
      ],
      "metadata": {
        "id": "2U9A9kh3OSWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnGRUDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n",
        "        super(AttnGRUDecoder, self).__init__()\n",
        "        self.t = 0 # (t)th token decoder\n",
        "        self.enc_hiddens = enc_hiddens # encoder output (B, L, hid_dim)\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(out_dim, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hid_dim, out_dim)\n",
        "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
        "  \n",
        "    def forward(self, input, hidden):\n",
        "        # s_i = f(s_(i-1), y_(i-1), c_i)\n",
        "        query = hidden.squeeze(0) # set query to calculate attention\n",
        "        query = torch.unsqueeze(query, dim=2) # query (B, hid_dim, 1) -> s_(i-1), self.enc_hiddens (B, L, hid_dim)\n",
        "        attn_score = torch.matmul(self.enc_hiddens, query)  # (B, L, 1)\n",
        "        attn_coef = F.softmax(attn_score, dim=1)\n",
        "        attn_val = (attn_coef * self.enc_hiddens).sum(dim=1, keepdim=True)  # (B, 1, hid_dim) -> c_i\n",
        "        attn_val = self.dropout_layer(attn_val)\n",
        "\n",
        "        input_embed = self.dropout_layer(self.embedding(input))   # (B, 1, emb_dim) -> y_(i-1)\n",
        "        input_cat = torch.concat([input_embed, attn_val], dim=-1)  # (B, 1, emb_dim + hid_dim) -> lstm input\n",
        "        \n",
        "        hiddens, hidden = self.gru(input_cat, hidden)  # hiddens -> (B, 1, hid_dim)\n",
        "        hidden_dropout = self.dropout_layer(hidden.squeeze(0))\n",
        "        oh_token_pred = F.log_softmax(self.classifier(hidden_dropout), dim=1) # (B, out_dim)\n",
        "        pred_token_idx = oh_token_pred.max(1)[1].unsqueeze(1) # (B, 1)\n",
        "\n",
        "        self.t += 1 # update time for each forward\n",
        "\n",
        "        return oh_token_pred, pred_token_idx, hidden"
      ],
      "metadata": {
        "id": "9-IRYjI6O0xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n",
        "        super(GRUSeq2Seq, self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.encoder = GRUEncoder(in_dim, emb_dim, hid_dim, dropout)\n",
        "        self.decoder = AttnGRUDecoder(emb_dim, hid_dim, out_dim, dropout)\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        batch_size, mx_len = src.shape\n",
        "        \n",
        "        # Encoder (start from zero-hidden & zero-cell states)\n",
        "        init_hidden = torch.zeros(1, batch_size, self.hid_dim).to(self.device)\n",
        "        enc_hiddens = self.encoder(src, init_hidden) # (B, L, hid_dim)\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder.enc_hiddens = enc_hiddens # set encoder's hidden states\n",
        "        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n",
        "        \n",
        "        # Decoder hidden/cell initialization\n",
        "        hidden = enc_hiddens[:, -1, :].unsqueeze(0)   # (1, B, hid_dim)\n",
        "\n",
        "        # First output token [SOS]\n",
        "        # trg -> (B, mx_len) => [SOS] : (B, 1) -> (B, 1, emb_dim)\n",
        "        input = trg[:, 0].unsqueeze(1) # (B, 1)\n",
        "        \n",
        "        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n",
        "            oh_token_pred, input, hidden = self.decoder(input, hidden)\n",
        "            outputs[t-1] = oh_token_pred  # oh_token_pred -> (B, num_output_words)\n",
        "\n",
        "        self.decoder.t=0 # after for loop, reset decoder's time to evaluate properly\n",
        "\n",
        "        outputs = torch.permute(outputs, (1, 2, 0))\n",
        "        # outputs -> (L, B, num_output_words) => (B, num_output_words, L)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "BOOj4_hhP83d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = dataset.input_lang.n_words\n",
        "out_dim = dataset.output_lang.n_words\n",
        "hid_dim = 1024 #256\n",
        "emb_dim = 1024 #256\n",
        "dropout = 0.5\n",
        "learning_rate=1e-3\n",
        "N_EPOCHS = 30\n",
        "valid_every=5\n",
        "best_valid_loss = float('inf')"
      ],
      "metadata": {
        "id": "c1RfJdjaREMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR as MultiStepLR\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gru_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=learning_rate)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)\n",
        "\n",
        "train_loss_list = []    # for every epoch\n",
        "valid_loss_list = []    # for every 5 epochs\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(gru_model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    train_loss_list.append(train_loss)\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.7f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(gru_model, valid_dataloader, loss_fn)\n",
        "        valid_loss_list.append(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            gru_model.decoder.t=0\n",
        "            torch.save(gru_model.state_dict(), 'gru-attn-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "usq_ohj4Qqf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6814814d-c55a-46e9-d8dc-59b6cbd266c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 3.1146916 | Train PPL:  22.526\n",
            "==========================\n",
            "\t Val. Loss: 2.481 |  Val. PPL:  11.953\n",
            "Epoch: 02\n",
            "\tTrain Loss: 2.3979342 | Train PPL:  11.000\n",
            "Epoch: 03\n",
            "\tTrain Loss: 2.0964141 | Train PPL:   8.137\n",
            "Epoch: 04\n",
            "\tTrain Loss: 1.8360295 | Train PPL:   6.272\n",
            "Epoch: 05\n",
            "\tTrain Loss: 1.6181364 | Train PPL:   5.044\n",
            "Epoch: 06\n",
            "\tTrain Loss: 1.4392182 | Train PPL:   4.217\n",
            "==========================\n",
            "\t Val. Loss: 1.710 |  Val. PPL:   5.531\n",
            "Epoch: 07\n",
            "\tTrain Loss: 1.2818150 | Train PPL:   3.603\n",
            "Epoch: 08\n",
            "\tTrain Loss: 1.1370130 | Train PPL:   3.117\n",
            "Epoch: 09\n",
            "\tTrain Loss: 1.0286618 | Train PPL:   2.797\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.9272217 | Train PPL:   2.527\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.7624662 | Train PPL:   2.144\n",
            "==========================\n",
            "\t Val. Loss: 1.610 |  Val. PPL:   5.003\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.7076680 | Train PPL:   2.029\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.6733205 | Train PPL:   1.961\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.6512425 | Train PPL:   1.918\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.6242630 | Train PPL:   1.867\n",
            "Epoch: 16\n",
            "\tTrain Loss: 0.6032311 | Train PPL:   1.828\n",
            "==========================\n",
            "\t Val. Loss: 1.600 |  Val. PPL:   4.955\n",
            "Epoch: 17\n",
            "\tTrain Loss: 0.5869459 | Train PPL:   1.798\n",
            "Epoch: 18\n",
            "\tTrain Loss: 0.5707425 | Train PPL:   1.770\n",
            "Epoch: 19\n",
            "\tTrain Loss: 0.5478372 | Train PPL:   1.730\n",
            "Epoch: 20\n",
            "\tTrain Loss: 0.5367564 | Train PPL:   1.710\n",
            "Epoch: 21\n",
            "\tTrain Loss: 0.5199211 | Train PPL:   1.682\n",
            "==========================\n",
            "\t Val. Loss: 1.607 |  Val. PPL:   4.987\n",
            "Epoch: 22\n",
            "\tTrain Loss: 0.5174364 | Train PPL:   1.678\n",
            "Epoch: 23\n",
            "\tTrain Loss: 0.5027137 | Train PPL:   1.653\n",
            "Epoch: 24\n",
            "\tTrain Loss: 0.4842698 | Train PPL:   1.623\n",
            "Epoch: 25\n",
            "\tTrain Loss: 0.4754136 | Train PPL:   1.609\n",
            "Epoch: 26\n",
            "\tTrain Loss: 0.4649307 | Train PPL:   1.592\n",
            "==========================\n",
            "\t Val. Loss: 1.588 |  Val. PPL:   4.896\n",
            "Epoch: 27\n",
            "\tTrain Loss: 0.4637252 | Train PPL:   1.590\n",
            "Epoch: 28\n",
            "\tTrain Loss: 0.4470660 | Train PPL:   1.564\n",
            "Epoch: 29\n",
            "\tTrain Loss: 0.4374548 | Train PPL:   1.549\n",
            "Epoch: 30\n",
            "\tTrain Loss: 0.4263664 | Train PPL:   1.532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "loaded_model.load_state_dict(torch.load('gru-attn-model.pt'))\n",
        "\n",
        "test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"
      ],
      "metadata": {
        "id": "WrFYlXfiRCSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355a514d-ae89-4e68-de6d-9d2974e1fcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Test. Loss: 1.546 |  Test. PPL:   4.693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train/validation loss visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(np.arange(1, N_EPOCHS+1), train_loss_list)\n",
        "#plt.plot(np.arange(1, N_EPOCHS, valid_every), valid_loss_list)\n",
        "plt.title('Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXvP9tYIx6S_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "20cd4143-4200-455b-c285-bb0da0c0ae59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(1, N_EPOCHS+1, valid_every), valid_loss_list)\n",
        "plt.title('Valid Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IKaLmQoHx7sP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "207e324e-bb00-4fe4-c70d-157ea93131f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Seq2Seq model with Transformer"
      ],
      "metadata": {
        "id": "qAZdJqTJXVcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Transformer Seq2Seq Model"
      ],
      "metadata": {
        "id": "t07UOwbpH7CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        \n",
        "        encoder_layer = TransformerEncoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, n_layers)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n",
        "        \n",
        "    def forward(self, src, pos_emb, src_mask):\n",
        "        '''\n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - pos_emb: positional embedding (max_len, hid_dim)\n",
        "        - src_mask: padding mask tensor for source sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of TransSeq2Seq.\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below,\n",
        "\n",
        "        - encoder output (B, max_len, hid_dim)\n",
        "        '''\n",
        "        batch_size, src_len = src.shape\n",
        "        \n",
        "        src_embed = self.tok_embedding(src) * self.scale  # (B, max_len, hid_dim)\n",
        "        # print(src_embed)\n",
        "        src_input = self.dropout(src_embed + pos_emb)     # (B, max_len, hid_dim)\n",
        "        \n",
        "        enc_output = self.encoder(src_input, src_key_padding_mask=src_mask)\n",
        "\n",
        "        return enc_output"
      ],
      "metadata": {
        "id": "Cvv3bN0qXX1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, out_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(out_dim, hid_dim)\n",
        "        \n",
        "        decoder_layer = TransformerDecoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, n_layers)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, out_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n",
        "        \n",
        "    def forward(self, trg, pos_emb, enc_src, trg_mask, trg_sub_mask, src_mask):\n",
        "        '''\n",
        "        INPUT\n",
        "        - trg: target language batched data (B, max_len)\n",
        "        - pos_emb: positional embedding (max_len, hid_dim)\n",
        "        - enc_src: encoder outputs (B, max_len, hid_dim)\n",
        "        - trg_mask: padding mask tensor for target sentences (B, max_len)\n",
        "        - trg_sub_mask: subsequent mask for target sentences (max_len, max_len)\n",
        "        - src_mask: padding mask tensor for source sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of TransSeq2Seq.\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below,\n",
        "\n",
        "        - decoder output (B, max_len, out_dim)\n",
        "        '''\n",
        "        batch_size, trg_len = trg.shape\n",
        "\n",
        "        trg_embed = self.tok_embedding(trg) * self.scale   # (B, max_len, hid_dim)\n",
        "        trg_input = self.dropout(trg_embed + pos_emb)     # (B, max_len, hid_dim)\n",
        "        # print(enc_src)\n",
        "        dec_output = self.decoder(tgt=trg_input, memory=enc_src,\n",
        "                                  tgt_mask=trg_sub_mask,\n",
        "                                  tgt_key_padding_mask=trg_mask,\n",
        "                                  memory_key_padding_mask=src_mask)\n",
        "        # dec_output = self.dropout(dec_output)\n",
        "        dec_output = self.fc_out(dec_output)\n",
        "        \n",
        "        return dec_output       # (B, max_len, out_dim)"
      ],
      "metadata": {
        "id": "8mKifSxjIWKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout_p, device, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.encoder = TransEncoder(in_dim, hid_dim, n_layers[0], n_heads, ff_dim, dropout_p, device)\n",
        "        self.decoder = TransDecoder(out_dim, hid_dim, n_layers[1], n_heads, ff_dim, dropout_p, device)\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        '''\n",
        "        INPUT\n",
        "        - src: batched input sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - Boolean padding mask tensor (B, max_len)\n",
        "        '''\n",
        "        # src_mask shape (B, max_len) is the argument 'src_key_padding_mask'\n",
        "        # for torch.nn.TransformerEncoder.forward()\n",
        "        # Position with True : Not allowed to attend\n",
        "        # Position with False : will be unchanged\n",
        "        src_padding_mask = (src == dataset.input_lang_pad).to(self.device)  # (B, max_len)\n",
        "        return src_padding_mas\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        '''\n",
        "        INPUT\n",
        "        - trg: batched target sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - A tuple of a padding mask tensor and a subsequent mask tensor ((B, max_len), (max_len, max_len))\n",
        "        '''\n",
        "        # Position with True : Not allowed to attend\n",
        "        # Position with False : will be unchanged\n",
        "        trg_padding_mask = (trg == dataset.output_lang_pad).to(self.device)   # (B, max_len)\n",
        "        trg_sub_mask = torch.triu(torch.ones((self.max_length, self.max_length)), diagonal=1).bool().to(self.device)\n",
        "\n",
        "        return trg_padding_mask, trg_sub_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        '''\n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - trg: target language batched data (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - decoder output (B, out_dim, max_len)\n",
        "        \n",
        "        '''\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask, trg_sub_mask = self.make_trg_mask(trg)\n",
        "        pos_emb = self.get_pos_emb()\n",
        "        enc_output = self.encoder(src=src, pos_emb=pos_emb, src_mask=src_mask)\n",
        "        dec_output = self.decoder(trg=trg, pos_emb=pos_emb, enc_src=enc_output, \n",
        "                                  trg_mask=trg_mask, trg_sub_mask=trg_sub_mask, \n",
        "                                  src_mask=src_mask)\n",
        "        dec_output = torch.permute(dec_output, (0, 2, 1))\n",
        "  \n",
        "        return dec_output\n",
        "    \n",
        "    \n",
        "    def get_pos_emb(self):\n",
        "        '''\n",
        "        OUTPUT\n",
        "        - positional embedding tensor (max_len, hid_dim)\n",
        "        '''\n",
        "        i = torch.arange(self.hid_dim).to(self.device)\n",
        "        divisor = 1 / torch.pow(10000, 2 * (i // 2) / self.hid_dim)    # (hid_dim,)\n",
        "        pos = torch.arange(self.max_length).view(-1, 1).to(self.device)     # (max_len, 1)\n",
        "        angles = pos * divisor        # (max_len, hid_dim)\n",
        "        pos_embedding = torch.zeros_like(angles).to(self.device)   # (max_len, hid_dim)\n",
        "        pos_embedding[:, 0::2] = torch.sin(angles[:, 0::2]).to(self.device)\n",
        "        pos_embedding[:, 1::2] = torch.cos(angles[:, 1::2]).to(self.device)\n",
        "\n",
        "        return pos_embedding        # (max_len, hid_dim)"
      ],
      "metadata": {
        "id": "L5VFP1-3IXmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "KqnvbugEIJ-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = dataset.input_lang.n_words\n",
        "out_dim = dataset.output_lang.n_words\n",
        "hid_dim = 256\n",
        "ff_dim = 1024\n",
        "n_enc_layers = 4\n",
        "n_dec_layers = 4\n",
        "n_layers = [n_enc_layers, n_dec_layers]\n",
        "n_heads = 8\n",
        "dropout = 0.3\n",
        "\n",
        "learning_rate=1e-4\n",
        "N_EPOCHS = 100\n",
        "valid_every=5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index = dataset.output_lang_pad)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "hdNx0Ol5ILbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = model.get_pos_emb()\n",
        "pe = pe.to('cpu')\n",
        "plt.pcolormesh(pe.squeeze(1), cmap='RdBu')\n",
        "print(pe.shape)\n",
        "\n",
        "\n",
        "plt.xlim((0, hid_dim))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "-X2Tl0yB4EC3",
        "outputId": "3aca0445-84ff-4976-a84f-f96d887bb9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            model.decoder.t=0\n",
        "            torch.save(model.state_dict(), 'transformer-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "aES3_sBTIgnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7bbcca-d76c-40a1-d5c4-7b19827dc06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 3.999 | Train PPL:  54.538\n",
            "==========================\n",
            "\t Val. Loss: 2.037 |  Val. PPL:   7.667\n",
            "Epoch: 02\n",
            "\tTrain Loss: 1.957 | Train PPL:   7.079\n",
            "Epoch: 03\n",
            "\tTrain Loss: 1.509 | Train PPL:   4.520\n",
            "Epoch: 04\n",
            "\tTrain Loss: 1.263 | Train PPL:   3.534\n",
            "Epoch: 05\n",
            "\tTrain Loss: 1.099 | Train PPL:   3.002\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.968 | Train PPL:   2.633\n",
            "==========================\n",
            "\t Val. Loss: 0.753 |  Val. PPL:   2.124\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.857 | Train PPL:   2.355\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.763 | Train PPL:   2.145\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.684 | Train PPL:   1.982\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.619 | Train PPL:   1.858\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.559 | Train PPL:   1.748\n",
            "==========================\n",
            "\t Val. Loss: 0.460 |  Val. PPL:   1.583\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.508 | Train PPL:   1.662\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.463 | Train PPL:   1.589\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.422 | Train PPL:   1.525\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.386 | Train PPL:   1.471\n",
            "Epoch: 16\n",
            "\tTrain Loss: 0.355 | Train PPL:   1.426\n",
            "==========================\n",
            "\t Val. Loss: 0.320 |  Val. PPL:   1.377\n",
            "Epoch: 17\n",
            "\tTrain Loss: 0.325 | Train PPL:   1.385\n",
            "Epoch: 18\n",
            "\tTrain Loss: 0.300 | Train PPL:   1.350\n",
            "Epoch: 19\n",
            "\tTrain Loss: 0.276 | Train PPL:   1.318\n",
            "Epoch: 20\n",
            "\tTrain Loss: 0.255 | Train PPL:   1.290\n",
            "Epoch: 21\n",
            "\tTrain Loss: 0.234 | Train PPL:   1.264\n",
            "==========================\n",
            "\t Val. Loss: 0.256 |  Val. PPL:   1.292\n",
            "Epoch: 22\n",
            "\tTrain Loss: 0.216 | Train PPL:   1.241\n",
            "Epoch: 23\n",
            "\tTrain Loss: 0.200 | Train PPL:   1.222\n",
            "Epoch: 24\n",
            "\tTrain Loss: 0.184 | Train PPL:   1.202\n",
            "Epoch: 25\n",
            "\tTrain Loss: 0.169 | Train PPL:   1.184\n",
            "Epoch: 26\n",
            "\tTrain Loss: 0.157 | Train PPL:   1.170\n",
            "==========================\n",
            "\t Val. Loss: 0.215 |  Val. PPL:   1.240\n",
            "Epoch: 27\n",
            "\tTrain Loss: 0.145 | Train PPL:   1.156\n",
            "Epoch: 28\n",
            "\tTrain Loss: 0.133 | Train PPL:   1.142\n",
            "Epoch: 29\n",
            "\tTrain Loss: 0.123 | Train PPL:   1.131\n",
            "Epoch: 30\n",
            "\tTrain Loss: 0.114 | Train PPL:   1.121\n",
            "Epoch: 31\n",
            "\tTrain Loss: 0.105 | Train PPL:   1.111\n",
            "==========================\n",
            "\t Val. Loss: 0.199 |  Val. PPL:   1.220\n",
            "Epoch: 32\n",
            "\tTrain Loss: 0.097 | Train PPL:   1.102\n",
            "Epoch: 33\n",
            "\tTrain Loss: 0.089 | Train PPL:   1.093\n",
            "Epoch: 34\n",
            "\tTrain Loss: 0.081 | Train PPL:   1.085\n",
            "Epoch: 35\n",
            "\tTrain Loss: 0.075 | Train PPL:   1.078\n",
            "Epoch: 36\n",
            "\tTrain Loss: 0.069 | Train PPL:   1.072\n",
            "==========================\n",
            "\t Val. Loss: 0.178 |  Val. PPL:   1.195\n",
            "Epoch: 37\n",
            "\tTrain Loss: 0.063 | Train PPL:   1.066\n",
            "Epoch: 38\n",
            "\tTrain Loss: 0.058 | Train PPL:   1.060\n",
            "Epoch: 39\n",
            "\tTrain Loss: 0.053 | Train PPL:   1.055\n",
            "Epoch: 40\n",
            "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
            "Epoch: 41\n",
            "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
            "==========================\n",
            "\t Val. Loss: 0.182 |  Val. PPL:   1.200\n",
            "Epoch: 42\n",
            "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
            "Epoch: 43\n",
            "\tTrain Loss: 0.037 | Train PPL:   1.038\n",
            "Epoch: 44\n",
            "\tTrain Loss: 0.033 | Train PPL:   1.034\n",
            "Epoch: 45\n",
            "\tTrain Loss: 0.029 | Train PPL:   1.030\n",
            "Epoch: 46\n",
            "\tTrain Loss: 0.027 | Train PPL:   1.027\n",
            "==========================\n",
            "\t Val. Loss: 0.177 |  Val. PPL:   1.193\n",
            "Epoch: 47\n",
            "\tTrain Loss: 0.024 | Train PPL:   1.025\n",
            "Epoch: 48\n",
            "\tTrain Loss: 0.022 | Train PPL:   1.022\n",
            "Epoch: 49\n",
            "\tTrain Loss: 0.019 | Train PPL:   1.020\n",
            "Epoch: 50\n",
            "\tTrain Loss: 0.018 | Train PPL:   1.018\n",
            "Epoch: 51\n",
            "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
            "==========================\n",
            "\t Val. Loss: 0.174 |  Val. PPL:   1.190\n",
            "Epoch: 52\n",
            "\tTrain Loss: 0.015 | Train PPL:   1.015\n",
            "Epoch: 53\n",
            "\tTrain Loss: 0.013 | Train PPL:   1.014\n",
            "Epoch: 54\n",
            "\tTrain Loss: 0.012 | Train PPL:   1.012\n",
            "Epoch: 55\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "Epoch: 56\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "==========================\n",
            "\t Val. Loss: 0.182 |  Val. PPL:   1.200\n",
            "Epoch: 57\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "Epoch: 58\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "Epoch: 59\n",
            "\tTrain Loss: 0.008 | Train PPL:   1.008\n",
            "Epoch: 60\n",
            "\tTrain Loss: 0.007 | Train PPL:   1.007\n",
            "Epoch: 61\n",
            "\tTrain Loss: 0.007 | Train PPL:   1.007\n",
            "==========================\n",
            "\t Val. Loss: 0.177 |  Val. PPL:   1.194\n",
            "Epoch: 62\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.006\n",
            "Epoch: 63\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.006\n",
            "Epoch: 64\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "Epoch: 65\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "Epoch: 66\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "==========================\n",
            "\t Val. Loss: 0.179 |  Val. PPL:   1.196\n",
            "Epoch: 67\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "Epoch: 68\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "Epoch: 69\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "Epoch: 70\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "Epoch: 71\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "==========================\n",
            "\t Val. Loss: 0.180 |  Val. PPL:   1.198\n",
            "Epoch: 72\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "Epoch: 73\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "Epoch: 74\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "Epoch: 75\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "Epoch: 76\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "==========================\n",
            "\t Val. Loss: 0.187 |  Val. PPL:   1.206\n",
            "Epoch: 77\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 78\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 79\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 80\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 81\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "==========================\n",
            "\t Val. Loss: 0.189 |  Val. PPL:   1.208\n",
            "Epoch: 82\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 83\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "Epoch: 84\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 85\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 86\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "==========================\n",
            "\t Val. Loss: 0.191 |  Val. PPL:   1.211\n",
            "Epoch: 87\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 88\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 89\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 90\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 91\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "==========================\n",
            "\t Val. Loss: 0.187 |  Val. PPL:   1.205\n",
            "Epoch: 92\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 93\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 94\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 95\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 96\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "==========================\n",
            "\t Val. Loss: 0.187 |  Val. PPL:   1.206\n",
            "Epoch: 97\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 98\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 99\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "Epoch: 100\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "loaded_model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n",
        "loaded_model.load_state_dict(torch.load('transformer-model.pt'))\n",
        "\n",
        "test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "4M6sUc-aJKP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1d79cb-af18-4b56-ac4c-7a604d24bcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Test. Loss: 0.187 |  Test. PPL:   1.206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gCswrEKrLeiQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hw4_translation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
